{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM3BgiKyAF+tJWh0Mkxu5hy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doyouneedanswer/infini-colab/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrYCybehFgLp",
        "outputId": "485e83c0-2071-43d2-e7b4-1d706c68d439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Существующая директория удалена.\n",
            "Репозиторий успешно клонирован.\n",
            "Файлы успешно скопированы в Colab.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from git import Repo\n",
        "\n",
        "# URL вашего репозитория на GitHub\n",
        "repo_url = 'https://github.com/doyouneedanswer/infini-colab.git'\n",
        "\n",
        "# Путь, куда клонировать репозиторий\n",
        "repo_path = '/content/infini-colab'\n",
        "\n",
        "# Удаление существующей директории, если она существует\n",
        "if os.path.exists(repo_path):\n",
        "    shutil.rmtree(repo_path)\n",
        "    print(\"Существующая директория удалена.\")\n",
        "\n",
        "# Клонирование репозитория\n",
        "Repo.clone_from(repo_url, repo_path)\n",
        "print(\"Репозиторий успешно клонирован.\")\n",
        "\n",
        "# Путь к файлу requirements.txt в клонированном репозитории\n",
        "requirements_file = os.path.join(repo_path, 'requirements.txt')\n",
        "\n",
        "# Путь к файлу весов модели в клонированном репозитории\n",
        "weights_file = os.path.join(repo_path, 'Plixel-SD-1.5.safetensors')\n",
        "\n",
        "# Копирование файлов в текущую рабочую директорию\n",
        "shutil.copy(requirements_file, '/content/requirements.txt')\n",
        "shutil.copy(weights_file, '/content/Plixel-SD-1.5.safetensors')\n",
        "\n",
        "print(\"Файлы успешно скопированы в Colab.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import torch\n",
        "from rembg import remove\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "import struct\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load Stable Diffusion model\n",
        "print(\"Loading SD...\")\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\", use_safetensors=True\n",
        ")\n",
        "print(\"Loaded SD, loading LoRA...\")\n",
        "\n",
        "# Load LoRA weights (Make sure to upload this file to Colab or set the correct path)\n",
        "pipeline.load_lora_weights(\"/content/Plixel-SD-1.5.safetensors\")  # Adjust path if needed\n",
        "\n",
        "# Check if CUDA is available and move to GPU if possible\n",
        "if torch.cuda.is_available():\n",
        "    pipeline.to(\"cuda\")\n",
        "    print(\"Using GPU for inference.\")\n",
        "else:\n",
        "    print(\"CUDA not available. Using CPU for inference.\")\n",
        "\n",
        "# Disable safety checker\n",
        "pipeline.safety_checker = lambda images, **kwargs: (images, [False] * len(images))\n",
        "print(\"Models loaded.\")\n",
        "\n",
        "# Function to generate texture\n",
        "def generate_texture(item_description: str):\n",
        "    print(\"Requesting texture for:\", item_description)\n",
        "    try:\n",
        "        # Generate image using the model\n",
        "        im = pipeline(\n",
        "            \"Minecraft item, \" + item_description + \" white background.\",\n",
        "            guidance_scale=8,\n",
        "            width=256,\n",
        "            height=256,\n",
        "            num_inference_steps=20,\n",
        "        ).images[0]\n",
        "\n",
        "        # Ensure image has a valid format\n",
        "        if im.format is None:\n",
        "            im.format = \"PNG\"\n",
        "            print(\"Format set to PNG.\")\n",
        "\n",
        "        # Save the image before background removal for debugging\n",
        "        im.save(\"generated_image_before_removal.png\", \"PNG\")\n",
        "        print(\"Image saved before background removal.\")\n",
        "\n",
        "        # Remove background\n",
        "        im = remove(im)\n",
        "\n",
        "        # Resize the image to 16x16 and convert to RGBA\n",
        "        im = im.resize((16, 16)).convert(\"RGBA\")\n",
        "\n",
        "        # Save the intermediate image for verification\n",
        "        im.save(\"resized_texture.png\", \"PNG\")\n",
        "        print(\"Saved resized texture for verification\")\n",
        "\n",
        "        # Prepare texture as a list of integers\n",
        "        texture = []\n",
        "        for x in range(16):\n",
        "            for y in range(16):\n",
        "                red, green, blue, alpha = im.getpixel((y, x))\n",
        "                if alpha < 10:\n",
        "                    texture.append(-1)\n",
        "                    continue\n",
        "                rgb = red\n",
        "                rgb = (rgb << 8) + green\n",
        "                rgb = (rgb << 8) + blue\n",
        "                texture.append(rgb)\n",
        "\n",
        "        # Convert texture to bytes (Base64)\n",
        "        texture_bytes = struct.pack(\">{}i\".format(len(texture)), *texture)\n",
        "        texture_b64 = base64.b64encode(texture_bytes).decode(\"utf-8\")\n",
        "\n",
        "        # Log the base64 length\n",
        "        print(f\"Base64 length: {len(texture_b64)}\")\n",
        "\n",
        "        # Save the original image as a result\n",
        "        im.save(\"generated_texture.png\", \"PNG\")\n",
        "        print(\"Generated texture saved as PNG.\")\n",
        "\n",
        "        return {\"success\": True, \"image\": texture_b64}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating texture: {e}\")\n",
        "        return {\"success\": False, \"message\": str(e)}\n",
        "\n",
        "# Define a route to generate textures via API\n",
        "@app.route('/generate', methods=['GET'])\n",
        "def generate():\n",
        "    item_description = request.args.get('itemDescription', None)\n",
        "\n",
        "    if item_description is None:\n",
        "        return jsonify({\"success\": False, \"message\": \"Item description is required!\"}), 400\n",
        "\n",
        "    try:\n",
        "        result = generate_texture(item_description)\n",
        "        return jsonify(result)\n",
        "    except Exception as e:\n",
        "        return jsonify({\"success\": False, \"message\": str(e)}), 500\n",
        "\n",
        "# Run the Flask app\n",
        "if __name__ == '__main__':\n",
        "    # Set up ngrok for tunneling\n",
        "    ngrok_auth_token = input(\"Enter your ngrok auth token: \")\n",
        "    ngrok.set_auth_token(ngrok_auth_token)\n",
        "\n",
        "    # Create the tunnel\n",
        "    public_url = ngrok.connect(17707)\n",
        "    print(f\"Public URL: {public_url}\")\n",
        "\n",
        "    # Start Flask server\n",
        "    app.run(port=17707)"
      ],
      "metadata": {
        "id": "aYUwuqGoFrKr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}